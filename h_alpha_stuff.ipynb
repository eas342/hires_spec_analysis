{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import ascii, fits\n",
    "from astropy.table import Table, vstack\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import es_gen\n",
    "import pdb\n",
    "import glob\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.convolution import Gaussian1DKernel, convolve\n",
    "import os\n",
    "import es_gen\n",
    "from sp_engine import subaruSpec, measuredArray, stellModel\n",
    "from specutils.io import read_fits\n",
    "from astropy.time import Time\n",
    "from copy import deepcopy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Originally, don't think H-alpha was covered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = subaruSpec('kic1255_fits/w111345.fits',columnUse=\"RawFlux\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(s.wave,s.normFlux)\n",
    "plt.ylim(0,2)\n",
    "plt.xlim(6560,6590)\n",
    "plt.axvline(6563.,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In a re-analysis, Kento did recover the H-alpha\n",
    "Collect all red spectra since that's where the H$\\alpha$ line is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fList = glob.glob('new_k1255_fits_w_halpha/w*.fits')\n",
    "redCCDList = []\n",
    "for oneFile in fList:\n",
    "    s = subaruSpec(oneFile)\n",
    "    if s.ccdSide == 'red':\n",
    "        redCCDList.append(oneFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather the Barycentric and Systematic velocities to apply the shifts to the star's rest frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvSystematic = -36.26 ## Croll et al. 2014 systematic RV + my offset to match Mg I lines\n",
    "baryCorr = ascii.read('output/barycent_corrections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFile = len(redCCDList)\n",
    "timeArray, headArray = [], []\n",
    "for ind,oneFile in enumerate(redCCDList):\n",
    "    baseName = os.path.basename(oneFile)\n",
    "    \n",
    "    ## Apply the RV barycentric and systematic correction\n",
    "    baryInd = baryCorr['File Name'] == baseName\n",
    "    if np.sum(baryInd) != 1:\n",
    "        print(\"Couldn't find RV correctly for file {}\".format(oneFile))\n",
    "    RV = baryCorr['RV (km/s)'][baryInd]\n",
    "    \n",
    "    #s = subaruSpec(oneFile,columnUse='Flux') ## this cleaned flux appears to have artifacts\n",
    "    #s = subaruSpec(oneFile,columnUse='RawFlux',rvCorrection=rvSystematic - RV)\n",
    "    #pdb.set_trace()\n",
    "    s = subaruSpec(oneFile,columnUse='RawFlux')\n",
    "    s2 = subaruSpec(oneFile,columnUse='RawFlux',rvCorrection=rvSystematic - RV)\n",
    "    \n",
    "    path1 = '../hirano/kic1255_20150827/{}'.format(baseName)\n",
    "    path2 = '../hirano/kic1255_20150828/{}'.format(baseName)\n",
    "    if os.path.exists(path1):\n",
    "        head = fits.getheader(path1)\n",
    "    elif os.path.exists(path2):\n",
    "        head = fits.getheader(path2)\n",
    "    else:\n",
    "        print('No original header found for {}'.format(basename))\n",
    "        head = {'DATE-OBS':\"NAN\",'UT-STR':\"NAN\"}\n",
    "    timeArray.append(\"{}T{}\".format(head['DATE-OBS'],head['UT-STR']))\n",
    "    headArray.append(head)\n",
    "    \n",
    "    if ind == 0:\n",
    "        ## Choose the wavelength grid the first time through\n",
    "        pts = (s.wave > 6559.4) & (s.wave < 6570.)\n",
    "        waveGrid = s.wave[pts]\n",
    "        allFlux = np.zeros([nFile,len(waveGrid)])\n",
    "        allFluxRV = np.zeros_like(allFlux)\n",
    "        ptsForNormalization = (waveGrid > 6558.) & (waveGrid < 6560.)\n",
    "    \n",
    "    for specInd, specObj in enumerate([s,s2]):\n",
    "        f = interp1d(specObj.wave,specObj.normFlux)\n",
    "        interpolatedFlux = f(waveGrid)\n",
    "        normFlux = interpolatedFlux/np.median(interpolatedFlux[ptsForNormalization])\n",
    "        if specInd == 0:\n",
    "            allFlux[ind,:] = normFlux\n",
    "        else:\n",
    "            allFluxRV[ind,:] = normFlux\n",
    "    \n",
    "    #print(\"File {}, Median={}\".format(oneFile,np.median(allFlux[:,ind])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medSpec = np.nanmedian(allFlux,axis=0)\n",
    "medSpecObj = measuredArray(waveGrid,medSpec,Res=6e4)\n",
    "medSpecObj.removePoly()\n",
    "## Get Errors from the standard deviation\n",
    "stdSpec = np.nanstd(allFlux,axis=0)\n",
    "medSNR = np.median(medSpec/stdSpec)\n",
    "medSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(waveGrid,medSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the time in the ApJ format (or what I think is the ApJ format they asked for in previous papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Time(timeArray,out_subfmt='')\n",
    "months =['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "tLabels = []\n",
    "for oneVal in timeArray:\n",
    "    oneMonth = months[int(oneVal[5:7])-1]\n",
    "    tLabel = \"{} {} {}, {}\".format(oneVal[0:4],oneMonth,oneVal[8:10],oneVal[11:16])\n",
    "    tLabels.append(tLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxList = [allFlux,allFluxRV]\n",
    "plotNames = ['Earth Frame','Stellar Frame']\n",
    "\n",
    "fig, axList = plt.subplots(2,figsize=(12,7))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for flux2D, name, ax in zip(fluxList,plotNames,axList):\n",
    "    for ind,oneRow in enumerate(flux2D):\n",
    "        ax.plot(waveGrid,oneRow - 0.1 * ind,label=tLabels[ind])\n",
    "    ax.set_xlabel(\"Wavelength ($\\AA$)\")\n",
    "    ax.set_ylabel(\"Normalized Flux\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim(6557,6566)\n",
    "    ax.set_ylim(-0.7,1.5)\n",
    "\n",
    "    NIST_ha_wavelength = 6562.79 ## NIST H-alpha wavelength in air\n",
    "    ax.axvline(NIST_ha_wavelength,alpha=0.7,linewidth=2,color='black') ## \n",
    "    ax.annotate(r'NIST H$\\alpha$',xy=(NIST_ha_wavelength,-0.7),\n",
    "                xytext=(6564,-0.5),\n",
    "               arrowprops={'facecolor':'black','shrink':0.05})\n",
    "    ax.set_title(name)\n",
    "    \n",
    "fig.savefig(\"plots/h_alpha_subaru.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make IRAF-friendly files for Johanna's analysis\n",
    "Only started to do this because we ended up pulling the H$\\alpha$ stuff out\n",
    "Needs some more work to put in an iraf-friendly format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepHeaders = ascii.read('input/header_keyword_to_keep.txt',data_start=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind,oneFile in enumerate(redCCDList):\n",
    "    baseName = os.path.basename(oneFile)\n",
    "    s = subaruSpec(oneFile)\n",
    "    \n",
    "    ## Choose the wavelength subset the first time through\n",
    "    pts = (s.wave > 6540.) & (s.wave < 6570.)\n",
    "    \n",
    "    tOut = Table()\n",
    "    tOut['Wave'] = s.wave[pts]\n",
    "    tOut['Flux'] = s.normFlux[pts]\n",
    "    #tOut.write('output/iraf_friendly/{}'.format(baseName),\n",
    "    #          overwrite=True)\n",
    "    binTable = fits.BinTableHDU(tOut)\n",
    "    ## Copy the header info\n",
    "    for oneTag in keepHeaders:\n",
    "        oneKey = oneTag[0]\n",
    "        binTable.header[oneKey] = head[oneKey]\n",
    "    \n",
    "    binTable.writeto('output/iraf_friendly/{}'.format(baseName),\n",
    "                     overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just Double Check Two of the ASCII files\n",
    "Why are they so similar for 2015 Aug 28?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#files=['w111549','w111553']\n",
    "files=['w111345','w111349']\n",
    "datArray = []\n",
    "for oneFile in files:\n",
    "    fitsDir = 'new_k1255_fits2_w_halpha/{}.fits'.format(oneFile)\n",
    "    if os.path.exists(fitsDir) == False:\n",
    "        dat = ascii.read('new_k1255_ascii_w_halpha/{}.txt'.format(oneFile),\n",
    "                         names=['wave','flat flux','flux'])\n",
    "        dat.write(fitsDir)\n",
    "    datArray.append(dat)\n",
    "#dat2 = ascii.read('new_k1255_ascii_w_halpha/w111349.txt',\n",
    "#                  names=['wave','flat flux','flux'])\n",
    "# dat = ascii.read('new_k1255_ascii_2nd_download/w111345.txt',\n",
    "#                 names=['wave','flat flux','flux'])\n",
    "# dat2 = ascii.read('new_k1255_ascii_2nd_download/w111349.txt',\n",
    "#                   names=['wave','flat flux','flux'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, the H-alpha flux looks like there's a repeat of the same spectrum? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,6))\n",
    "plotThickness=[3,1]\n",
    "\n",
    "fluxArray = []\n",
    "for oneInd,oneDat in enumerate(datArray):\n",
    "    pts = (oneDat['wave'] > 6557) & (oneDat['wave'] < 6566)\n",
    "    fluxArray.append(oneDat['flat flux'][pts])\n",
    "    ax.plot(oneDat['wave'][pts],oneDat['flat flux'][pts],'.',\n",
    "            linewidth=plotThickness[oneInd],\n",
    "            markersize=plotThickness[oneInd] * 3,\n",
    "            label=files[oneInd])\n",
    "ax.legend()\n",
    "ax.set_xlabel(r'Wavelength ($\\AA$)')\n",
    "ax.set_ylabel('Flux')\n",
    "ax.set_ylim(0,1500)\n",
    "fig.savefig('plots/spectra_check.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = subaruSpec('new_k1255_fits_w_halpha/w111345.fits')\n",
    "s2 = subaruSpec('new_k1255_fits_w_halpha/w111345.fits',columnUse='RawFlux')\n",
    "s.normalize(region=[6558,6566])\n",
    "s2.normalize(region=[6558,6566])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, there is an apparent emission in the line's core, but this comes from the data cleaning process to make the \"flat flux\" for RV purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = (s.wave > 6557) & (s.wave < 6566)\n",
    "plt.plot(s.wave[pts],s.normFlux[pts],label='Cleaned Flux')\n",
    "plt.plot(s2.wave[pts],s2.normFlux[pts],label='Raw Flux')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
